{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hough_TransForm.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZFUSrU89aW8NXXIwN0UUo6C6GSFF4TU8",
      "authorship_tag": "ABX9TyPq+wWtD6U4R9J1lDvyhtuL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FreshWaterLee/Personal_Stduy_Deep/blob/main/Hough_TransForm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8tMiIYw4KOn"
      },
      "source": [
        "## 허프변환 알고리즘을 이용한 라인검출\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/road/Road1.jpg')\n",
        "dst = img.copy()\n",
        "dst2 = img.copy()\n",
        "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "## Canny 엣지 검출을 위한 그레이 스케일\n",
        "gray = cv2.GaussianBlur(imgGray,(7,7),0)\n",
        "canny = cv2.Canny(gray,5000,1500,apertureSize=5,L2gradient=True)\n",
        "## Canny 엣지 알고리즘(그레이 스케일화 한 이미지,최소 임계값,최대 임계값)\n",
        "\n",
        "## 허프 변환 알고리즘보다는 허프 변환 플러스 알고리즘을 사용하는것을 추천!!\n",
        "\n",
        "lines = cv2.HoughLines(canny,0.8,np.pi/180,150,srn=100,stn=200,min_theta=0,max_theta=np.pi)\n",
        "## cv2.HoughLines(검출 이미지, 거리, 각도, 임곗값, 거리 약수, 각도 약수, 최소 각도, 최대 각도)\n",
        "## cv2.HoughLines함수는 가장 직선일 확률이 높은 거리와 각도를 반환한다.\n",
        "## 예전에는 허프변환을 주로 사용했지만 현재는 더 정밀한 함수를 사용할수 있기에 굳이 사용을...?\n",
        "\n",
        "lines2 = cv2.HoughLinesP(canny,0.8,np.pi/180,90,minLineLength=10,maxLineGap=100)\n",
        "## cv2.HoughLinesP(검출 이미지, 거리, 각도, 임곗값, 최소 선 길이, 최대 선 간격)\n",
        "## 함수의 매개변수를 조금씩 변환하면서 라인을 검출하는 방법을 추천한다.\n",
        "## 굳이 허프변환을 사용하고 각도를 조건삼아서 검출하는 것보다는\n",
        "\n",
        "\n",
        "for i in lines2:\n",
        "    cv2.line(dst2,(i[0][0],i[0][1]),(i[0][2],i[0][3]),(0,0,255),2)\n",
        "    ## x1,y1,x2,y2의 순서로 시작점과 끝점을 표시\n",
        "\n",
        "for i in lines:\n",
        "    rho, theta = i[0][0],i[0][1]\n",
        "    ## 거리와 각도를 변수에 저장\n",
        "    deg = math.degrees(theta)\n",
        "    ## math 라이브러리의 각도 검출 함수를 사용(라디안 값이 매개변수)\n",
        "    a,b = np.cos(theta),np.sin (theta)\n",
        "    x0,y0 = a*rho,b*rho\n",
        "\n",
        "    scale = img.shape[0] + img.shape[1]\n",
        "    x1 = int(x0+scale*-b)\n",
        "    y1 = int(y0+scale*a)\n",
        "    x2 = int(x0-scale*-b)\n",
        "    y2 = int(x0-scale*a)\n",
        "\n",
        "    cv2.line(dst,(x1,y1),(x2,y2),(0,0,255),2)\n",
        "    cv2.circle(dst,(x0,y0),3,(255,0,0),5,cv2.FILLED)\n",
        "\n",
        "cv2_imshow(dst)\n",
        "cv2_imshow(dst2)\n",
        "## 결과를 보면 점진성 확률정 허프 변환이 차선과 같은 라인 검출의 정확성이 높기 때문\n",
        "cv2.waitKey(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIM97RN4PHsk"
      },
      "source": [
        "## 허프변환 알고리즘을 이용한 라인검출\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/road/Road1.jpg')\n",
        "dst = img.copy()\n",
        "dst2 = img.copy()\n",
        "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "## Canny 엣지 검출을 위한 그레이 스케일\n",
        "canny = cv2.Canny(gray,5000,1500,apertureSize=5,L2gradient=True)\n",
        "## Canny 엣지 알고리즘(그레이 스케일화 한 이미지,최소 임계값,최대 임계값)\n",
        "\n",
        "## 허프 변환 알고리즘보다는 허프 변환 플러스 알고리즘을 사용하는것을 추천!!\n",
        "\n",
        "lines2 = cv2.HoughLinesP(canny,0.8,np.pi/180,90,minLineLength=10,maxLineGap=100)\n",
        "## cv2.HoughLinesP(검출 이미지, 거리, 각도, 임곗값, 최소 선 길이, 최대 선 간격)\n",
        "## 함수의 매개변수를 조금씩 변환하면서 라인을 검출하는 방법을 추천한다.\n",
        "## 블러를 안하는게 검출의 정확성이 높아진다.\n",
        "\n",
        "for i in lines2:\n",
        "    cv2.line(dst2,(i[0][0],i[0][1]),(i[0][2],i[0][3]),(0,0,255),2)\n",
        "    ## x1,y1,x2,y2의 순서로 시작점과 끝점을 표시\n",
        "\n",
        "cv2_imshow(dst2)\n",
        "cv2_imshow(canny)\n",
        "## 결과를 보면 점진성 확률정 허프 변환이 차선과 같은 라인 검출의 정확성이 높기 때문\n",
        "cv2.waitKey(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-__vZg5Yt9T"
      },
      "source": [
        "## 모폴로지 연산\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/road/Road2.jpg',cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "kernel = cv2.getStructuringElement(cv2.MORPH_CROSS,(9,9))\n",
        "\n",
        "dst = cv2.morphologyEx(img,cv2.MORPH_OPEN,kernel,iterations=9)\n",
        "## 원본 배열(이미지), 연산 방법, 구조 요소, 고정점, 반복 횟수)\n",
        "##\n",
        "\n",
        "cv2_imshow(dst)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK2OX5Ed1_jC"
      },
      "source": [
        "## 허프 변환 알고리즘을 이용한 원 검출 알고리즘\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "src = cv2.imread('/content/drive/MyDrive/road/Colorball.jpg')\n",
        "dst = src.copy()\n",
        "gray = cv2.cvtColor(src,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT,1,100,param1=250,param2=10,minRadius=80, maxRadius=120)\n",
        "## cv2.HoughCircles(검출 이미지, 검출 방법, 해상도 비율, 최소 거리, 캐니 엣지 임곗값, 중심 임곗값, 최소 반지름, 최대 반지름)\n",
        "\n",
        "for i in circles[0]:\n",
        "    cv2.circle(dst,(i[0],i[1]),i[2],(255,255,255),5)\n",
        "\n",
        "cv2_imshow(dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aocttz3S43gY"
      },
      "source": [
        "## 이미지 연산\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "src = cv2.imread(\"/content/drive/MyDrive/road/Pencil.jpg\")\n",
        "number1 = np.ones_like(src) * 127\n",
        "number2 = np.ones_like(src) * 2\n",
        "\n",
        "add = cv2.add(src, number1)\n",
        "sub = cv2.subtract(src, number1)\n",
        "mul = cv2.multiply(src, number2)\n",
        "div = cv2.divide(src, number2)\n",
        "\n",
        "src = np.concatenate((src, src, src, src), axis = 1)\n",
        "## 이미지 연결 함수\n",
        "\n",
        "number = np.concatenate((number1, number1, number2, number2), axis = 1)\n",
        "dst = np.concatenate((add, sub, mul, div), axis = 1)\n",
        "\n",
        "dst = np.concatenate((src, number, dst), axis = 0)\n",
        "\n",
        "cv2_imshow(dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m2PjVwr6xmU"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "src = cv2.imread('/content/drive/MyDrive/road/analy.jpg')\n",
        "gray = cv2.cvtColor(src,cv2.COLOR_BGR2GRAY)\n",
        "_, binary = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
        "\n",
        "_and = cv2.bitwise_and(gray,binary)\n",
        "_or = cv2.bitwise_or(gray,binary)\n",
        "_xor = cv2.bitwise_xor(gray,binary)\n",
        "_not = cv2.bitwise_not(gray,binary)\n",
        "\n",
        "src = np.concatenate((np.zeros_like(gray),gray,binary,np.zeros_like(gray)),axis=1)\n",
        "dst = np.concatenate((_and,_or,_xor,_not),axis=1)\n",
        "dst = np.concatenate((src,dst),axis=0)\n",
        "\n",
        "cv2_imshow(dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5v0LFhF_1gI"
      },
      "source": [
        "## 히스토그램을 이용한 픽셀 값 분포도 그래프 작성\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/road/road3.jpg')\n",
        "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "result = np.zeros((img.shape[0],256),dtype=np.uint8)\n",
        "\n",
        "hist = cv2.calcHist([gray],[0],None,[256],[0,256])\n",
        "##cv2.calcHist(연산 이미지, 특정 채널, 마스크, 히스토그램 크기, 히스토그램 범위)\n",
        "\n",
        "# 특정 채널은 차원 수(DIMS)를 설정합니다. 그레이스케일 이미지는 단일 채널이므로, 0을 사용합니다.\n",
        "# 마스크는 특정 영역에 대해서만 연산할 때 사용합니다. 해당 영역은 없으므로, None을 할당합니다.\n",
        "# 히스토그램 크기는 빈도 수(BINS)를 설정합니다. 픽셀의 범위는 0 ~ 255 이므로, [256]을 할당합니다.\n",
        "# 히스토그램 범위는 범위(RANGE)를 설정합니다. 예외 사항이 없으므로, 0 ~ 255의 범위를 계산하기 위해 [0, 256]을 할당합니다.\n",
        "\n",
        "cv2.normalize(hist,hist,0,result.shape[0],cv2.NORM_MINMAX)\n",
        "### 데이터 정규화\n",
        "\n",
        "\n",
        "for x,y in enumerate(hist):\n",
        "    cv2.line(result, (x, result.shape[0]), (x, result.shape[0] - y), 255)\n",
        "\n",
        "dst = np.hstack([gray,result])\n",
        "cv2_imshow(dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy5pPG4XCcxU"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "gray = np.linspace(0,255,num=90000,endpoint=True,retstep=False,dtype=np.uint8).reshape(300,300,1)\n",
        "color = np.zeros((300,300,3),np.uint8)\n",
        "color[0:150,:,0] =gray[0:150,:,0]\n",
        "color[:,150:300,2] =gray[:,150:300,0]\n",
        "\n",
        "x,y,c = 200,100,0\n",
        "access_gray = gray[y,x,c]\n",
        "access_color_blue = color[y,x,c]\n",
        "access_color = color[y,x]\n",
        "\n",
        "print(access_gray)\n",
        "print(access_color_blue)\n",
        "print(access_color)\n",
        "\n",
        "cv2_imshow(gray)\n",
        "cv2_imshow(color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMqcQq1sEmcF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}